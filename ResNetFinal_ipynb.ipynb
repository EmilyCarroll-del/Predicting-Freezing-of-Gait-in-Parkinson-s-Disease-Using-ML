{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilyCarroll-del/Predicting-Freezing-of-Gait-in-Parkinson-s-Disease-Using-ML/blob/main/ResNetFinal_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQg4zyBO-L2Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N4RXjxI-QsR",
        "outputId": "792e338a-ab94-4d76-d883-02757b870d46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_NkmZyb-R7C",
        "outputId": "dc8f85bd-1599-4bbe-c470-57f8ff7c157c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            " FFT.ipynb                                 ResNetNew.ipynb\n",
            " RandomForestFinalPreprocessedData.ipynb   \u001b[0m\u001b[01;34mTest-Data\u001b[0m/\n",
            "'Random Forest_Its_broken_now.ipynb'       \u001b[01;34mtlvmc-parkinsons-freezing-gait-prediction\u001b[0m/\n",
            " RandomForestNew.ipynb                     \u001b[01;34mTraining-Data\u001b[0m/\n",
            " ResNetFinal.ipynb.ipynb                   Untitled0.ipynb\n",
            " ResNet.ipynb                              Untitled1.ipynb\n",
            " ResNetNewBasicModel.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_directory(directory):\n",
        "    dfs = []\n",
        "    for file_name in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, file_name)\n",
        "\n",
        "        # Check if the file is a CSV and process it\n",
        "        if file_name.endswith('.csv') and os.path.isfile(file_path):\n",
        "            df = pd.read_csv(file_path) #read csv files\n",
        "            df['source_directory'] = os.path.basename(directory)  # Add a column to identify the source directory\n",
        "            df['csv_name'] = os.path.basename(file_name)\n",
        "            dfs.append(df)\n",
        "\n",
        "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()"
      ],
      "metadata": {
        "id": "7N5vdmY4-SZ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data from CSV files"
      ],
      "metadata": {
        "id": "xoKqPg2zELrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#directory to each folder in train\n",
        "train_defog_dir = '/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/train/defog'\n",
        "train_tdcsfog_dir = '/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog'\n",
        "\n",
        "#train_notype_dir = '/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/train/notype'"
      ],
      "metadata": {
        "id": "6ingUycC-U7A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each subdirectory\n",
        "defog = process_directory(train_defog_dir)\n",
        "tdcsfog = process_directory(train_tdcsfog_dir)\n",
        "#notype = process_directory(train_notype_dir)\n",
        "\n",
        "#train_df = pd.concat(train_data, ignore_index=True)\n",
        "print(\"Data concatenation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmnpSXzy-WVT",
        "outputId": "27037a3f-1e67-4971-b1bc-c0ba4e399289"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data concatenation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test CSV files\n",
        "defog_test_dir = '/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/test/defog.csv'\n",
        "tdcsfog_test_dir = '/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/test/tdcsfog.csv'"
      ],
      "metadata": {
        "id": "kplTTqVk-Xvn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#csv files -> df\n",
        "defog_test = pd.read_csv(defog_test_dir)\n",
        "tdcsfog_test = pd.read_csv(tdcsfog_test_dir)"
      ],
      "metadata": {
        "id": "UFruWa-J-ZhY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "bbjcOM2qEGXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing missing values of defog test and training data\n",
        "#defog dataset, valid = false, task = false; tdcsfog has no missing values\n",
        "defog = defog[defog['Valid']]\n",
        "defog = defog[defog['Task']]\n",
        "\n",
        "defog_test = defog_test[defog_test['Valid']]\n",
        "defog_test = defog_test[defog_test['Task']]"
      ],
      "metadata": {
        "id": "9UuyJ68EBUvz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(defog.head())\n",
        "print(defog_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ixa38w0BYR-",
        "outputId": "4efcb586-df00-4c6d-ddc6-5d98de184643"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "1000  1000 -0.970018  0.061626 -0.265625                0     0        0   \n",
            "1001  1001 -0.984375  0.044497 -0.265625                0     0        0   \n",
            "1002  1002 -0.984375  0.029016 -0.265625                0     0        0   \n",
            "1003  1003 -0.984375  0.015625 -0.265625                0     0        0   \n",
            "1004  1004 -0.984670  0.015330 -0.265625                0     0        0   \n",
            "\n",
            "      Valid  Task source_directory        csv_name  \n",
            "1000   True  True            defog  02ea782681.csv  \n",
            "1001   True  True            defog  02ea782681.csv  \n",
            "1002   True  True            defog  02ea782681.csv  \n",
            "1003   True  True            defog  02ea782681.csv  \n",
            "1004   True  True            defog  02ea782681.csv  \n",
            "      Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "1000  1000 -0.976776 -0.104293  0.182096                0     0        0   \n",
            "1001  1001 -0.977049 -0.106393  0.182613                0     0        0   \n",
            "1002  1002 -0.975982 -0.106688  0.182188                0     0        0   \n",
            "1003  1003 -0.904200 -0.080405  0.173685                0     0        0   \n",
            "1004  1004 -0.985695 -0.114734  0.192869                0     0        0   \n",
            "\n",
            "      Valid  Task  \n",
            "1000   True  True  \n",
            "1001   True  True  \n",
            "1002   True  True  \n",
            "1003   True  True  \n",
            "1004   True  True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop a small amount of outliers -defog train data\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate z-scores for each accelerometer axis\n",
        "defog[\"AccV_z\"] = zscore(defog[\"AccV\"])\n",
        "defog[\"AccML_z\"] = zscore(defog[\"AccML\"])\n",
        "defog[\"AccAP_z\"] = zscore(defog[\"AccAP\"])\n",
        "\n",
        "# Set threshold range for z-scores (-5 < z < 5)\n",
        "threshold = 5\n",
        "\n",
        "# Find rows where any component exceeds the threshold\n",
        "outliers = (defog[\"AccV_z\"].abs() > threshold) | \\\n",
        "           (defog[\"AccML_z\"].abs() > threshold) | \\\n",
        "           (defog[\"AccAP_z\"].abs() > threshold)\n",
        "\n",
        "# Filter out these rows from the dataset\n",
        "defog = defog[~outliers].drop(columns=[\"AccV_z\", \"AccML_z\", \"AccAP_z\"])\n",
        "\n",
        "# Save or inspect the filtered DataFrame\n",
        "print(\"Number of points dropped:\", outliers.sum())\n",
        "print(defog.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j67Vte2aBabo",
        "outputId": "e36f181b-4fba-43e5-eea4-448ed834914f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of points dropped: 11644\n",
            "      Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "1000  1000 -0.970018  0.061626 -0.265625                0     0        0   \n",
            "1001  1001 -0.984375  0.044497 -0.265625                0     0        0   \n",
            "1002  1002 -0.984375  0.029016 -0.265625                0     0        0   \n",
            "1003  1003 -0.984375  0.015625 -0.265625                0     0        0   \n",
            "1004  1004 -0.984670  0.015330 -0.265625                0     0        0   \n",
            "\n",
            "      Valid  Task source_directory        csv_name  \n",
            "1000   True  True            defog  02ea782681.csv  \n",
            "1001   True  True            defog  02ea782681.csv  \n",
            "1002   True  True            defog  02ea782681.csv  \n",
            "1003   True  True            defog  02ea782681.csv  \n",
            "1004   True  True            defog  02ea782681.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop a small amount of outliers -defog test\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate z-scores for each accelerometer axis\n",
        "defog_test[\"AccV_z\"] = zscore(defog_test[\"AccV\"])\n",
        "defog_test[\"AccML_z\"] = zscore(defog_test[\"AccML\"])\n",
        "defog_test[\"AccAP_z\"] = zscore(defog_test[\"AccAP\"])\n",
        "\n",
        "# Set threshold range for z-scores (-5 < z < 5)\n",
        "threshold = 5\n",
        "\n",
        "# Find rows where any component exceeds the threshold\n",
        "outliers = (defog_test[\"AccV_z\"].abs() > threshold) | \\\n",
        "           (defog_test[\"AccML_z\"].abs() > threshold) | \\\n",
        "           (defog_test[\"AccAP_z\"].abs() > threshold)\n",
        "\n",
        "# Filter out these rows from the dataset\n",
        "defog_test = defog_test[~outliers].drop(columns=[\"AccV_z\", \"AccML_z\", \"AccAP_z\"])\n",
        "\n",
        "# Save or inspect the filtered DataFrame\n",
        "print(\"Number of points dropped:\", outliers.sum())\n",
        "print(defog_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8XXvh0oBedd",
        "outputId": "8e78bbc0-c017-4798-c377-857033b1a4f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of points dropped: 349\n",
            "      Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "1000  1000 -0.976776 -0.104293  0.182096                0     0        0   \n",
            "1001  1001 -0.977049 -0.106393  0.182613                0     0        0   \n",
            "1002  1002 -0.975982 -0.106688  0.182188                0     0        0   \n",
            "1003  1003 -0.904200 -0.080405  0.173685                0     0        0   \n",
            "1004  1004 -0.985695 -0.114734  0.192869                0     0        0   \n",
            "\n",
            "      Valid  Task  \n",
            "1000   True  True  \n",
            "1001   True  True  \n",
            "1002   True  True  \n",
            "1003   True  True  \n",
            "1004   True  True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop a small amount of outliers -tdcsfog training\n",
        "\n",
        "# Calculate z-scores for each accelerometer axis\n",
        "tdcsfog[\"AccV_z\"] = zscore(tdcsfog[\"AccV\"])\n",
        "tdcsfog[\"AccML_z\"] = zscore(tdcsfog[\"AccML\"])\n",
        "tdcsfog[\"AccAP_z\"] = zscore(tdcsfog[\"AccAP\"])\n",
        "\n",
        "# Set threshold range for z-scores (-5 < z < 5)\n",
        "threshold = 5\n",
        "\n",
        "# Find rows where any component exceeds the threshold\n",
        "outliers = (tdcsfog[\"AccV_z\"].abs() > threshold) | \\\n",
        "           (tdcsfog[\"AccML_z\"].abs() > threshold) | \\\n",
        "           (tdcsfog[\"AccAP_z\"].abs() > threshold)\n",
        "\n",
        "# Filter out these rows from the dataset\n",
        "tdcsfog = tdcsfog[~outliers].drop(columns=[\"AccV_z\", \"AccML_z\", \"AccAP_z\"])\n",
        "\n",
        "# Save or inspect the filtered DataFrame\n",
        "print(\"Number of points dropped:\", outliers.sum())\n",
        "print(tdcsfog.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGnjtQ3cBhNQ",
        "outputId": "753dd247-e65e-4daf-d7e0-479cd359f108"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of points dropped: 27184\n",
            "   Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "0     0 -9.533939  0.566322 -1.413525                0     0        0   \n",
            "1     1 -9.536140  0.564137 -1.440621                0     0        0   \n",
            "2     2 -9.529345  0.561765 -1.429332                0     0        0   \n",
            "3     3 -9.531239  0.564227 -1.415490                0     0        0   \n",
            "4     4 -9.540825  0.561854 -1.429471                0     0        0   \n",
            "\n",
            "  source_directory        csv_name  \n",
            "0          tdcsfog  003f117e14.csv  \n",
            "1          tdcsfog  003f117e14.csv  \n",
            "2          tdcsfog  003f117e14.csv  \n",
            "3          tdcsfog  003f117e14.csv  \n",
            "4          tdcsfog  003f117e14.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop a small amount of outliers -tdcsfog test\n",
        "\n",
        "# Calculate z-scores for each accelerometer axis\n",
        "tdcsfog_test[\"AccV_z\"] = zscore(tdcsfog_test[\"AccV\"])\n",
        "tdcsfog_test[\"AccML_z\"] = zscore(tdcsfog_test[\"AccML\"])\n",
        "tdcsfog_test[\"AccAP_z\"] = zscore(tdcsfog_test[\"AccAP\"])\n",
        "\n",
        "# Set threshold range for z-scores (-5 < z < 5)\n",
        "threshold = 5\n",
        "\n",
        "# Find rows where any component exceeds the threshold\n",
        "outliers = (tdcsfog_test[\"AccV_z\"].abs() > threshold) | \\\n",
        "           (tdcsfog_test[\"AccML_z\"].abs() > threshold) | \\\n",
        "           (tdcsfog_test[\"AccAP_z\"].abs() > threshold)\n",
        "\n",
        "# Filter out these rows from the dataset\n",
        "tdcsfog_test = tdcsfog_test[~outliers].drop(columns=[\"AccV_z\", \"AccML_z\", \"AccAP_z\"])\n",
        "\n",
        "# Save or inspect the filtered DataFrame\n",
        "print(\"Number of points dropped:\", outliers.sum())\n",
        "print(tdcsfog_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmPvXWjJBjqa",
        "outputId": "6541b91d-f27b-4d1b-c2ff-580e122ebe4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of points dropped: 235\n",
            "   Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking\n",
            "0     0 -9.851042 -0.111723 -1.172427                0     0        0\n",
            "1     1 -9.849299 -0.116912 -1.173887                0     0        0\n",
            "2     2 -9.847808 -0.115431 -1.176858                0     0        0\n",
            "3     3 -9.848214 -0.103538 -1.177636                0     0        0\n",
            "4     4 -9.850402 -0.104952 -1.179113                0     0        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the accelerometer data - defog training & testing\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "fs = 100  # Sampling frequency in Hz\n",
        "\n",
        "# Define filter parameters\n",
        "lowcut = 0.25\n",
        "highcut = 10.0\n",
        "order = 4  # Filter order\n",
        "\n",
        "# Create a Butterworth bandpass filter\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "b, a = butter(order, [low, high], btype=\"band\")\n",
        "\n",
        "# Apply the filter to each accelerometer axis\n",
        "defog[\"AccV_filtered\"] = filtfilt(b, a, defog[\"AccV\"])\n",
        "defog[\"AccML_filtered\"] = filtfilt(b, a, defog[\"AccML\"])\n",
        "defog[\"AccAP_filtered\"] = filtfilt(b, a, defog[\"AccAP\"])\n",
        "\n",
        "defog_test[\"AccV_filtered\"] = filtfilt(b, a, defog_test[\"AccV\"])\n",
        "defog_test[\"AccML_filtered\"] = filtfilt(b, a, defog_test[\"AccML\"])\n",
        "defog_test[\"AccAP_filtered\"] = filtfilt(b, a, defog_test[\"AccAP\"])\n",
        "\n",
        "print(defog.head())\n",
        "print(defog_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEkKCsTLBmyO",
        "outputId": "b7f31cf2-fd3f-4db4-f070-34d2cb9a630c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "1000  1000 -0.970018  0.061626 -0.265625                0     0        0   \n",
            "1001  1001 -0.984375  0.044497 -0.265625                0     0        0   \n",
            "1002  1002 -0.984375  0.029016 -0.265625                0     0        0   \n",
            "1003  1003 -0.984375  0.015625 -0.265625                0     0        0   \n",
            "1004  1004 -0.984670  0.015330 -0.265625                0     0        0   \n",
            "\n",
            "      Valid  Task source_directory        csv_name  AccV_filtered  \\\n",
            "1000   True  True            defog  02ea782681.csv      -0.002409   \n",
            "1001   True  True            defog  02ea782681.csv      -0.008514   \n",
            "1002   True  True            defog  02ea782681.csv      -0.014268   \n",
            "1003   True  True            defog  02ea782681.csv      -0.019375   \n",
            "1004   True  True            defog  02ea782681.csv      -0.023621   \n",
            "\n",
            "      AccML_filtered  AccAP_filtered  \n",
            "1000       -0.028097        0.003932  \n",
            "1001       -0.043759        0.003981  \n",
            "1002       -0.057533        0.004027  \n",
            "1003       -0.068014        0.004066  \n",
            "1004       -0.074621        0.004092  \n",
            "      Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "1000  1000 -0.976776 -0.104293  0.182096                0     0        0   \n",
            "1001  1001 -0.977049 -0.106393  0.182613                0     0        0   \n",
            "1002  1002 -0.975982 -0.106688  0.182188                0     0        0   \n",
            "1003  1003 -0.904200 -0.080405  0.173685                0     0        0   \n",
            "1004  1004 -0.985695 -0.114734  0.192869                0     0        0   \n",
            "\n",
            "      Valid  Task  AccV_filtered  AccML_filtered  AccAP_filtered  \n",
            "1000   True  True       0.000002       -0.000828       -0.000223  \n",
            "1001   True  True       0.003406       -0.000863        0.000509  \n",
            "1002   True  True       0.005426       -0.001328        0.001359  \n",
            "1003   True  True       0.005318       -0.002424        0.002341  \n",
            "1004   True  True       0.003289       -0.004007        0.003321  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the accelerometer data - tdcsfog training and testing\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "fs = 128  # Sampling frequency in Hz\n",
        "\n",
        "# Define filter parameters\n",
        "lowcut = 0.25\n",
        "highcut = 10.0\n",
        "order = 4  # Filter order\n",
        "\n",
        "# Create a Butterworth bandpass filter\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "b, a = butter(order, [low, high], btype=\"band\")\n",
        "\n",
        "# Apply the filter to each accelerometer axis\n",
        "tdcsfog[\"AccV_filtered\"] = filtfilt(b, a, tdcsfog[\"AccV\"])\n",
        "tdcsfog[\"AccML_filtered\"] = filtfilt(b, a, tdcsfog[\"AccML\"])\n",
        "tdcsfog[\"AccAP_filtered\"] = filtfilt(b, a, tdcsfog[\"AccAP\"])\n",
        "\n",
        "tdcsfog_test[\"AccV_filtered\"] = filtfilt(b, a, tdcsfog_test[\"AccV\"])\n",
        "tdcsfog_test[\"AccML_filtered\"] = filtfilt(b, a, tdcsfog_test[\"AccML\"])\n",
        "tdcsfog_test[\"AccAP_filtered\"] = filtfilt(b, a, tdcsfog_test[\"AccAP\"])\n",
        "\n",
        "print(tdcsfog.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C7lq7HZEY8U",
        "outputId": "40afc694-ff25-4627-e14a-e7f3ec7ed15a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "0     0 -9.533939  0.566322 -1.413525                0     0        0   \n",
            "1     1 -9.536140  0.564137 -1.440621                0     0        0   \n",
            "2     2 -9.529345  0.561765 -1.429332                0     0        0   \n",
            "3     3 -9.531239  0.564227 -1.415490                0     0        0   \n",
            "4     4 -9.540825  0.561854 -1.429471                0     0        0   \n",
            "\n",
            "  source_directory        csv_name  AccV_filtered  AccML_filtered  \\\n",
            "0          tdcsfog  003f117e14.csv       0.001085        0.000976   \n",
            "1          tdcsfog  003f117e14.csv       0.000987       -0.000830   \n",
            "2          tdcsfog  003f117e14.csv       0.000909       -0.002732   \n",
            "3          tdcsfog  003f117e14.csv       0.000867       -0.004787   \n",
            "4          tdcsfog  003f117e14.csv       0.000862       -0.006999   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0        0.006895  \n",
            "1        0.003351  \n",
            "2        0.000218  \n",
            "3       -0.002184  \n",
            "4       -0.003691  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "defog = defog.drop(columns=['AccV', 'AccML', 'AccAP'])\n",
        "defog_test = defog_test.drop(columns=['AccV', 'AccML', 'AccAP'])\n",
        "\n",
        "tdcsfog = tdcsfog.drop(columns=['AccV', 'AccML', 'AccAP'])\n",
        "tdcsfog_test = tdcsfog_test.drop(columns=['AccV', 'AccML', 'AccAP'])"
      ],
      "metadata": {
        "id": "AyU5JoS2Ebwo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog = defog.reset_index(drop=True)\n",
        "defog_test = defog_test.reset_index(drop=True)\n",
        "\n",
        "tdcsfog = tdcsfog.reset_index(drop=True)\n",
        "tdcsfog_test = tdcsfog_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "M2V9bL2_Ed1V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog = defog.drop(columns = ['Task', 'source_directory', 'Valid', 'csv_name', 'Time'])\n",
        "defog_test = defog_test.drop(columns = ['Task', 'Valid', 'Time'])"
      ],
      "metadata": {
        "id": "3ct7jtQdEfgE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdcsfog = tdcsfog.drop(columns = ['source_directory', 'csv_name', 'Time'])\n",
        "tdcsfog_test = tdcsfog_test.drop(columns = ['Time'])"
      ],
      "metadata": {
        "id": "u9Q7vmlDEg6o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(defog.head())\n",
        "print(defog_test.head())\n",
        "print(tdcsfog.head())\n",
        "print(tdcsfog_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugR_UEV4EjRL",
        "outputId": "34e4d47b-9d2b-441a-aa8e-f2fbc404a296"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   StartHesitation  Turn  Walking  AccV_filtered  AccML_filtered  \\\n",
            "0                0     0        0      -0.002409       -0.028097   \n",
            "1                0     0        0      -0.008514       -0.043759   \n",
            "2                0     0        0      -0.014268       -0.057533   \n",
            "3                0     0        0      -0.019375       -0.068014   \n",
            "4                0     0        0      -0.023621       -0.074621   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0        0.003932  \n",
            "1        0.003981  \n",
            "2        0.004027  \n",
            "3        0.004066  \n",
            "4        0.004092  \n",
            "   StartHesitation  Turn  Walking  AccV_filtered  AccML_filtered  \\\n",
            "0                0     0        0       0.000002       -0.000828   \n",
            "1                0     0        0       0.003406       -0.000863   \n",
            "2                0     0        0       0.005426       -0.001328   \n",
            "3                0     0        0       0.005318       -0.002424   \n",
            "4                0     0        0       0.003289       -0.004007   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0       -0.000223  \n",
            "1        0.000509  \n",
            "2        0.001359  \n",
            "3        0.002341  \n",
            "4        0.003321  \n",
            "   StartHesitation  Turn  Walking  AccV_filtered  AccML_filtered  \\\n",
            "0                0     0        0       0.001085        0.000976   \n",
            "1                0     0        0       0.000987       -0.000830   \n",
            "2                0     0        0       0.000909       -0.002732   \n",
            "3                0     0        0       0.000867       -0.004787   \n",
            "4                0     0        0       0.000862       -0.006999   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0        0.006895  \n",
            "1        0.003351  \n",
            "2        0.000218  \n",
            "3       -0.002184  \n",
            "4       -0.003691  \n",
            "   StartHesitation  Turn  Walking  AccV_filtered  AccML_filtered  \\\n",
            "0                0     0        0       0.006816       -0.002987   \n",
            "1                0     0        0       0.007072       -0.002236   \n",
            "2                0     0        0       0.007328       -0.001456   \n",
            "3                0     0        0       0.007589       -0.000633   \n",
            "4                0     0        0       0.007863        0.000221   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0        0.022124  \n",
            "1        0.019785  \n",
            "2        0.017684  \n",
            "3        0.016030  \n",
            "4        0.014961  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segment Data"
      ],
      "metadata": {
        "id": "FeE_wCKLYrpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_rate_tdcsfog = 128 # 128 samples per second\n",
        "sample_rate_defog = 100"
      ],
      "metadata": {
        "id": "nsYLEWygY3Rv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "\n",
        "def segment_input_data(df, input_columns, sampling_rate, window_size_seconds=3, step_size_seconds=1):\n",
        "    \"\"\"\n",
        "    Segments time-series input data (accelerometer values) into overlapping windows.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Input DataFrame with time-series data.\n",
        "        input_columns (list of str): List of column names for input data (e.g., accelerometer).\n",
        "        window_size_seconds (int): Size of each window in seconds.\n",
        "        step_size_seconds (int): Step size for sliding windows in seconds.\n",
        "        sampling_rate (int): Sampling rate of the time-series data (e.g., 128 Hz).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Segmented input data of shape (num_windows, time_steps, input_features).\n",
        "    \"\"\"\n",
        "    # Calculate the number of samples per window and step\n",
        "    window_size_samples = int(window_size_seconds * sampling_rate)\n",
        "    step_size_samples = int(step_size_seconds * sampling_rate)\n",
        "\n",
        "    inputs = []\n",
        "\n",
        "    # Segment the input data (accelerometer values)\n",
        "    for start_idx in range(0, len(df) - window_size_samples + 1, step_size_samples):\n",
        "        # Segment input columns (accelerometer values)\n",
        "        input_window = df[input_columns].iloc[start_idx : start_idx + window_size_samples].values\n",
        "        inputs.append(input_window)\n",
        "\n",
        "    return np.array(inputs)"
      ],
      "metadata": {
        "id": "mvcxASWsYtxd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_output_data(df, output_columns, sampling_rate, window_size_seconds=3, step_size_seconds=1):\n",
        "    \"\"\"\n",
        "    Segments time-series output data (binary labels) into overlapping windows and aggregates them.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Input DataFrame with time-series data.\n",
        "        output_columns (list of str): List of column names for output data (e.g., binary labels).\n",
        "        window_size_seconds (int): Size of each window in seconds.\n",
        "        step_size_seconds (int): Step size for sliding windows in seconds.\n",
        "        sampling_rate (int): Sampling rate of the time-series data (e.g., 128 Hz).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Segmented output data of shape (num_windows, output_features).\n",
        "    \"\"\"\n",
        "    # Calculate the number of samples per window and step\n",
        "    window_size_samples = int(window_size_seconds * sampling_rate)\n",
        "    step_size_samples = int(step_size_seconds * sampling_rate)\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    # Segment the output data (binary labels)\n",
        "    for start_idx in range(0, len(df) - window_size_samples + 1, step_size_samples):\n",
        "        # Aggregate output columns (e.g., most common label within the window)\n",
        "        output_window = df[output_columns].iloc[start_idx : start_idx + window_size_samples]\n",
        "        output_values = mode(output_window, axis=0).mode[0]  # Most common value\n",
        "        outputs.append(output_values)\n",
        "    return np.array(outputs)"
      ],
      "metadata": {
        "id": "bsZne3z2FpoV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = ['AccV_filtered', 'AccML_filtered', 'AccAP_filtered']\n",
        "Turn = [\"Turn\"]\n",
        "SH = [\"StartHesitation\"]\n",
        "W = [\"Walking\"]"
      ],
      "metadata": {
        "id": "X3d8js3FBfEJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog_segments_X_train= segment_input_data(defog, X, sample_rate_defog)"
      ],
      "metadata": {
        "id": "yF_ftlYIY2fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog_segments_X_test= segment_input_data(defog_test, X, sample_rate_defog)"
      ],
      "metadata": {
        "id": "dfj1bg7QZc8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog_segments_y_train_T= segment_output_data(defog, Turn, sample_rate_defog)\n",
        "defog_segments_y_train_SH= segment_output_data(defog, SH, sample_rate_defog)\n",
        "defog_segments_y_train_W= segment_output_data(defog, W, sample_rate_defog)"
      ],
      "metadata": {
        "id": "t4s6qacaZxkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog_segments_y_test_T= segment_output_data(defog_test, Turn, sample_rate_defog)\n",
        "defog_segments_y_test_SH= segment_output_data(defog_test, SH, sample_rate_defog)\n",
        "defog_segments_y_test_W= segment_output_data(defog_test, W, sample_rate_defog)"
      ],
      "metadata": {
        "id": "55SgOdLW9K8m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "1bc9edfa-40ad-40f8-a813-8039e9c9a606"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'segment_output_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f0dbe2944395>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdefog_segments_y_test_T\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msegment_output_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefog_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTurn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate_defog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdefog_segments_y_test_SH\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msegment_output_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefog_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate_defog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdefog_segments_y_test_W\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msegment_output_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefog_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate_defog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'segment_output_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(defog_segments_X_train.shape)\n",
        "print(defog_segments_X_test.shape)\n",
        "print(defog_segments_y_train_T.shape)\n",
        "print(defog_segments_y_test_T.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXBDmLGF_U0k",
        "outputId": "bba10ed6-c2ae-461f-c791-a4a59476cbda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1974, 3000, 3)\n",
            "(63, 3000, 3)\n",
            "(1974,)\n",
            "(63,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_E2t0utMS9BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdcsfog_segments_X_train= segment_input_data(tdcsfog, X, sample_rate_tdcsfog)\n"
      ],
      "metadata": {
        "id": "pnWHy6RTLimI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "493a6b07-81fd-4b94-91cb-d27f1f913ebf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d4b855fe1a06>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtdcsfog_segments_X_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msegment_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdcsfog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate_tdcsfog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-8cc5f3be789d>\u001b[0m in \u001b[0;36msegment_input_data\u001b[0;34m(df, input_columns, sampling_rate, window_size_seconds, step_size_seconds)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Segment input columns (accelerometer values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0minput_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4117\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4131\u001b[0m             )\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4135\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         return self.reindex_indexer(\n\u001b[0m\u001b[1;32m    895\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[0m\u001b[1;32m    681\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[1;32m    841\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;31m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1308\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tdcsfog_segments_X_test= segment_input_data(tdcsfog_test, X, sample_rate_tdcsfog)"
      ],
      "metadata": {
        "id": "tcKh5mrvh8P5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdcsfog_segments_y_train_T= segment_output_data(tdcsfog, Turn, sample_rate_tdcsfog)\n",
        "tdcsfog_segments_y_train_SH= segment_output_data(tdcsfog, SH, sample_rate_tdcsfog)\n",
        "tdcsfog_segments_y_train_W= segment_output_data(tdcsfog, W, sample_rate_tdcsfog)"
      ],
      "metadata": {
        "id": "LNbQYqAhLtNd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdcsfog_segments_y_test_T= segment_output_data(tdcsfog_test, Turn, sample_rate_tdcsfog)\n",
        "tdcsfog_segments_y_test_SH= segment_output_data(tdcsfog_test, SH, sample_rate_tdcsfog)\n",
        "tdcsfog_segments_y_test_W= segment_output_data(tdcsfog_test, W, sample_rate_tdcsfog)"
      ],
      "metadata": {
        "id": "YKOoSbtML18w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "JDyyroYAEpji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TORCH_INDUCTOR_DISABLE\"] = \"1\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "JKPiRXhG_2mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/YasinShafiei/ResNet-From-Scratch/blob/main/architectures.py\n",
        "#https://github.com/janbrederecke/fog/blob/main/src/model.py"
      ],
      "metadata": {
        "id": "6TSAjASHBQix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _padding(downsample, kernel_size):\n",
        "    \"\"\"Compute required padding\"\"\"\n",
        "    padding = (kernel_size - 1) // 2\n",
        "    return padding"
      ],
      "metadata": {
        "id": "W88kNQCUj6pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _downsample(n_samples_in, n_samples_out):\n",
        "    \"\"\"Compute downsample rate\"\"\"\n",
        "    downsample = int(n_samples_in // n_samples_out)\n",
        "    if downsample < 1:\n",
        "        raise ValueError(\"Number of samples should always decrease\")\n",
        "    if n_samples_in % n_samples_out != 0:\n",
        "        raise ValueError(\n",
        "            \"Number of samples for two consecutive blocks \"\n",
        "            \"should always decrease by an integer factor.\"\n",
        "        )\n",
        "    return downsample\n"
      ],
      "metadata": {
        "id": "Xl7Q69vxkBJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample, kernel_size, dropout_rate):\n",
        "        if kernel_size % 2 == 0:\n",
        "            raise ValueError(\"This implementation only supports odd `kernel_size`.\")\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # Forward path\n",
        "        padding = _padding(1, kernel_size)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, bias=False)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        padding = _padding(downsample, kernel_size)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding, stride=downsample, bias=False)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Skip connection\n",
        "        skip_connection_layers = []\n",
        "        if downsample > 1:\n",
        "            maxpool = nn.MaxPool1d(downsample, stride=downsample)\n",
        "            skip_connection_layers.append(maxpool)\n",
        "\n",
        "        if in_channels != out_channels:\n",
        "            conv1x1 = nn.Conv1d(in_channels, out_channels, 1, bias=False)\n",
        "            skip_connection_layers.append(conv1x1)\n",
        "\n",
        "        self.skip_connection = nn.Sequential(*skip_connection_layers) if skip_connection_layers else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply skip connection (if needed)\n",
        "        if self.skip_connection is not None:\n",
        "            y = self.skip_connection(x)\n",
        "        else:\n",
        "            y = x  # No change to input if no skip connection\n",
        "\n",
        "        # 1st layer\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # 2nd layer\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        # Add skip connection (if present)\n",
        "        x += y\n",
        "\n",
        "        # Final batch norm, ReLU, and dropout\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "MP73P9Ca-ylT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Residual Network for 1D accelerometer data.\n",
        "class SmallResNet(nn.Module):\n",
        "    def __init__(self, input_dim, blocks_dim, n_classes, kernel_size=17, dropout_rate=0.8):\n",
        "        super(SmallResNet, self).__init__()\n",
        "\n",
        "        # First layers\n",
        "        in_channels, out_channels = input_dim[0], blocks_dim[0][0]\n",
        "        downsample = 1\n",
        "        padding = (kernel_size - 1) // 2  # Adjust padding for odd kernel size\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, bias=False, stride=downsample, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        # Residual block layers\n",
        "        self.res_blocks = nn.ModuleList()\n",
        "        for i, (n_filters, n_samples) in enumerate(blocks_dim):\n",
        "            in_channels, out_channels = out_channels, n_filters\n",
        "            resblk1d = BasicBlock(in_channels, n_filters, downsample, kernel_size, dropout_rate)\n",
        "            self.res_blocks.append(resblk1d)\n",
        "\n",
        "        # Linear layer\n",
        "        n_filters_last, n_samples_last = blocks_dim[-1]\n",
        "        self.lin = nn.Linear(n_filters_last, n_classes)\n",
        "        self.n_blk = len(blocks_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First layers\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        # Residual blocks\n",
        "        y = x\n",
        "        for blk in self.res_blocks:\n",
        "            x = blk(x)  # Only pass the input tensor, not the skip connection\n",
        "\n",
        "        # Flatten array\n",
        "        x = x.mean(-1)\n",
        "\n",
        "        logits = self.lin(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "jRSBzIbT_Q7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Model"
      ],
      "metadata": {
        "id": "LJMeR_-sEr4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Qxb19rimwqNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AccelerometerBinaryDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (numpy array or tensor): Shape (num_samples, sequence_length)\n",
        "            labels (numpy array or tensor): Shape (num_samples,)\n",
        "        \"\"\"\n",
        "        # Convert DataFrame to NumPy array if necessary\n",
        "        if isinstance(data, pd.DataFrame):\n",
        "            data = data.values  # Convert DataFrame to NumPy array\n",
        "        if isinstance(labels, (pd.DataFrame, pd.Series)):\n",
        "            labels = labels.values\n",
        "\n",
        "        # Ensure data is 2D (num_samples, sequence_length)\n",
        "        if data.ndim == 2:  # Use ndim for numpy arrays\n",
        "            data = np.expand_dims(data, axis=1)  # Add a channel dimension: shape becomes (num_samples, 1, sequence_length)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)  # Shape (num_samples, 1, sequence_length)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Shape (num_samples,)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "K85fkYnPxJ0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model initialization\n",
        "input_dim = (3, sample_rate_defog)  # 3 input features\n",
        "blocks_dim = [(16, 1), (32, 1), (64, 1)]  # Example block dimensions\n",
        "n_classes = 3\n",
        "model = SmallResNet(input_dim=input_dim, blocks_dim=blocks_dim, n_classes=n_classes,  kernel_size=17,dropout_rate=0.0,)\n"
      ],
      "metadata": {
        "id": "OrAY9tYDqLPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check input and output shapes\n",
        "test_input = torch.randn(32, 3, 128)  # Batch of 32, 3 channels, sequence length 128\n",
        "test_output = model(test_input)\n",
        "print(f\"Output shape: {test_output.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54BqjLRd4jXB",
        "outputId": "ac32931a-8159-4e97-d5bb-4ce8903fe0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([32, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # For multi-class or binary classification"
      ],
      "metadata": {
        "id": "j4gdr_bUwyDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "FmrEI0yi76s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpBSyE22wVds",
        "outputId": "374c25af-abe2-41ee-c562-b9c6a36ffa13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SmallResNet(\n",
            "  (conv1): Conv1d(3, 16, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (res_blocks): ModuleList(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv1d(16, 16, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "      (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): LeakyReLU(negative_slope=0.01)\n",
            "      (dropout1): Dropout(p=0.0, inplace=False)\n",
            "      (conv2): Conv1d(16, 16, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "      (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout2): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv1d(16, 32, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): LeakyReLU(negative_slope=0.01)\n",
            "      (dropout1): Dropout(p=0.0, inplace=False)\n",
            "      (conv2): Conv1d(32, 32, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout2): Dropout(p=0.0, inplace=False)\n",
            "      (skip_connection): Sequential(\n",
            "        (0): Conv1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv1d(32, 64, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): LeakyReLU(negative_slope=0.01)\n",
            "      (dropout1): Dropout(p=0.0, inplace=False)\n",
            "      (conv2): Conv1d(64, 64, kernel_size=(17,), stride=(1,), padding=(8,), bias=False)\n",
            "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (dropout2): Dropout(p=0.0, inplace=False)\n",
            "      (skip_connection): Sequential(\n",
            "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lin): Linear(in_features=64, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "# Training loop\n",
        "  num_epochs = 3  # Number of epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs_batch, labels_batch in train_loader:\n",
        "        inputs_batch = inputs_batch.permute(0, 2, 1)  # Change shape from [batch_size, num_time_steps, num_channels] to [batch_size, num_channels, num_time_steps]\n",
        "\n",
        "        optimizer.zero_grad()  # Zero gradients from previous iteration\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels_batch)\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels_batch.size(0)\n",
        "        correct += (predicted == labels_batch).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "816Oxdqs6r5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape the data for defog turn\n",
        "train_dataset_defog_Turn = AccelerometerBinaryDataset(defog_segments_X_train, defog_segments_y_train_T)\n",
        "test_dataset_defog_Turn = AccelerometerBinaryDataset(defog_segments_X_test, defog_segments_y_test_T)"
      ],
      "metadata": {
        "id": "Gp8VIAdbw5vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_defog_Turn = DataLoader(train_dataset_defog_Turn, batch_size=32, shuffle=True)\n",
        "test_loader_defog_Turn = DataLoader(test_dataset_defog_Turn, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "Ymbdv22ILctA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape the data for defog walking\n",
        "train_dataset_defog_W = AccelerometerBinaryDataset(defog_segments_X_train, defog_segments_y_train_W)\n",
        "test_dataset_defog_W = AccelerometerBinaryDataset(defog_segments_X_test, defog_segments_y_test_W)\n",
        "\n",
        "train_loader_defog_W = DataLoader(train_dataset_defog_W, batch_size=32, shuffle=True)\n",
        "test_loader_defog_W = DataLoader(test_dataset_defog_W, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "j9STZTYc3EnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape the data for defog StartHesitation\n",
        "train_dataset_defog_SH = AccelerometerBinaryDataset(defog_segments_X_train, defog_segments_y_train_SH)\n",
        "test_dataset_defog_SH = AccelerometerBinaryDataset(defog_segments_X_test, defog_segments_y_test_SH)\n",
        "\n",
        "train_loader_defog_SH = DataLoader(train_dataset_defog_SH, batch_size=32, shuffle=True)\n",
        "test_loader_defog_SH= DataLoader(test_dataset_defog_SH, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "IUZYmLaI3SIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape data for tdcsfog Turn\n",
        "train_dataset_tdcsfog_Turn = AccelerometerBinaryDataset(tdcsfog_segments_X_train, tdcsfog_segments_y_train_T)\n",
        "train_loader_tdcsfog_Turn = DataLoader(train_dataset_tdcsfog_Turn, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset_tdcsfog_Turn = AccelerometerBinaryDataset(tdcsfog_segments_X_test, tdcsfog_segments_y_test_T)\n",
        "test_loader_tdcsfog_Turn = DataLoader(test_dataset_tdcsfog_Turn, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "CrGNJSimnJJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape data for tdcsfog StartHesitation\n",
        "train_dataset_tdcsfog_SH = AccelerometerBinaryDataset(tdcsfog_segments_X_train, tdcsfog_segments_y_train_SH)\n",
        "train_loader_tdcsfog_SH = DataLoader(train_dataset_tdcsfog_SH, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset_tdcsfog_SH = AccelerometerBinaryDataset(tdcsfog_segments_X_test, tdcsfog_segments_y_test_SH)\n",
        "test_loader_tdcsfog_SH = DataLoader(test_dataset_tdcsfog_SH, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "aBwufBx4pLmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shape data for tdcsfog Walking\n",
        "train_dataset_tdcsfog_W = AccelerometerBinaryDataset(tdcsfog_segments_X_train, tdcsfog_segments_y_train_W)\n",
        "train_loader_tdcsfog_W= DataLoader(train_dataset_tdcsfog_W, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset_tdcsfog_W = AccelerometerBinaryDataset(tdcsfog_segments_X_test, tdcsfog_segments_y_test_W)\n",
        "test_loader_tdcsfog_W= DataLoader(test_dataset_tdcsfog_W, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "7Zp5VGglq1im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train model\n",
        "train_defog_turn_model = train_model(model, train_loader_defog_Turn, criterion, optimizer, epochs= 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYblmGX4w7oH",
        "outputId": "5bf661f9-a5db-4ba4-d45e-eb95e5b9950d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.4998, Accuracy: 87.59%\n",
            "Epoch [2/3], Loss: 0.4722, Accuracy: 87.59%\n",
            "Epoch [3/3], Loss: 0.4513, Accuracy: 87.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_defog_W_model = train_model(model, train_loader_defog_W, criterion, optimizer, epochs = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3SsRaBy3gPC",
        "outputId": "5bc1c977-f95a-4fbc-c5ce-6a9253be856b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.9685, Accuracy: 78.32%\n",
            "Epoch [2/3], Loss: 0.7007, Accuracy: 98.83%\n",
            "Epoch [3/3], Loss: 0.5325, Accuracy: 98.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_defog_SH_model = train_model(model, train_loader_defog_SH, criterion, optimizer, epochs = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weW2dl6v7Gfi",
        "outputId": "b3081358-67b0-4e79-8348-c4aa5a0bc25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 0.8859, Accuracy: 88.45%\n",
            "Epoch [2/3], Loss: 0.6481, Accuracy: 100.00%\n",
            "Epoch [3/3], Loss: 0.4885, Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tdcsfog_turn_model = train_model(model, train_loader_tdcsfog_Turn, criterion, optimizer, epochs = 3)"
      ],
      "metadata": {
        "id": "U8OZPt7FF94N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tdcsfog_W_model = train_model(model, train_loader_tdcsfog_W, criterion, optimizer, epochs = 3)"
      ],
      "metadata": {
        "id": "DaakTPTtGWSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tdcsfog_SH_model = train_model(model, train_loader_tdcsfog_SH, criterion, optimizer, epochs = 3)"
      ],
      "metadata": {
        "id": "qQKWKqYbGcmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "fZrbxBSEEvyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import roc_curve\n"
      ],
      "metadata": {
        "id": "rvodfKpYON7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []  # Store all predictions\n",
        "    all_labels = []  # Store all true labels\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients during evaluation\n",
        "        for inputs_batch, labels_batch in test_loader:\n",
        "            inputs_batch = inputs_batch.permute(0, 2, 1)  # Ensure correct shape for Conv1d\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs_batch)\n",
        "\n",
        "            # If binary classification, apply sigmoid and threshold\n",
        "            if outputs.shape[1] == 1:  # Single output for binary classification\n",
        "                predicted = (outputs > 0.5).cpu().numpy()  # Apply threshold\n",
        "            else:\n",
        "                _, predicted = torch.max(outputs, 1)  # Multi-class classification\n",
        "\n",
        "            # Collect predictions and true labels\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels_batch.cpu().numpy())\n",
        "\n",
        "    # Calculate Precision, Recall, and Weighted F1 Score\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
        "\n",
        "    # Print the metrics\n",
        "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "    print(f\"F1 Score (Weighted): {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "um4QIqQdOid3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `model` is your trained model and `test_loader` is your DataLoader for the test dataset\n",
        "evaluate_model(model, test_loader_defog_Turn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Feq0CoTQWokL",
        "outputId": "3143c577-5632-4e69-979a-360c0c752420"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision (Weighted): 0.7727\n",
            "Recall (Weighted): 0.6508\n",
            "F1 Score (Weighted): 0.5131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defog Walking\n",
        "print(\"Evaluation for Walking defog events in Defog\")\n",
        "evaluate_model(model, test_loader_defog_W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaaMksP6fyso",
        "outputId": "9f447d25-5e19-4f32-e0ec-b75fdb129543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for Walking defog events in Defog\n",
            "Precision (Weighted): 1.0000\n",
            "Recall (Weighted): 1.0000\n",
            "F1 Score (Weighted): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defog Walking\n",
        "print(\"Evaluation for SH defog events in Defog\")\n",
        "evaluate_model(model, test_loader_defog_SH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oeu6ZcQbgOJw",
        "outputId": "f601828d-af1a-4067-f73b-169cf726a6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for SH defog events in Defog\n",
            "Precision (Weighted): 1.0000\n",
            "Recall (Weighted): 1.0000\n",
            "F1 Score (Weighted): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tdcsfog Turn\n",
        "print(\"Evaluation for Turn FOG events in tdcsfog\")\n",
        "evaluate_model(model, test_loader_tdcsfog_Turn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxsihDn2hByw",
        "outputId": "a84b755c-14b5-456a-f41a-d1155928a051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for Turn FOG events in tdcsfog\n",
            "Precision (Weighted): 0.7578\n",
            "Recall (Weighted): 0.5882\n",
            "F1 Score (Weighted): 0.4357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tdcsfog SH\n",
        "print(\"Evaluation for SH FOG events in tdcsfog\")\n",
        "evaluate_model(model, test_loader_tdcsfog_SH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPAn_r2xpGI1",
        "outputId": "3a372ec8-507a-4567-dc7c-b3baf6ed0cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for SH FOG events in tdcsfog\n",
            "Precision (Weighted): 0.7924\n",
            "Recall (Weighted): 0.2941\n",
            "F1 Score (Weighted): 0.1337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tdcsfog SH\n",
        "print(\"Evaluation for W FOG events in tdcsfog\")\n",
        "evaluate_model(model, test_loader_tdcsfog_W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bKvo49Jpl4u",
        "outputId": "a6365299-d397-4e89-8db6-0ca2e99d8729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation for W FOG events in tdcsfog\n",
            "Precision (Weighted): 0.8962\n",
            "Recall (Weighted): 0.1176\n",
            "F1 Score (Weighted): 0.0248\n"
          ]
        }
      ]
    }
  ]
}