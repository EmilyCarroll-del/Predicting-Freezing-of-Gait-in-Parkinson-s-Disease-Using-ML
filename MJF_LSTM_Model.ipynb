{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilyCarroll-del/Michael-J-Fox-Foundation-FOG-in-PD/blob/main/MJF_LSTM_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8ew0oyHrKW4",
        "outputId": "77728c20-9a56-4d4e-c345-9cee1f0200b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Colab Notebooks/'\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUe0u_o5rYwO",
        "outputId": "a8ceb796-f951-4710-9bb3-83eb00e7e611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            "'Copy of defog_start_hesitation.csv'          defog_turn_draft.csv\n",
            "'Copy of defog_start_hesitation_test.csv'     defog_turn_test_draft.csv\n",
            "'Copy of defog_turn.csv'                      defog_walk_draft.csv\n",
            "'Copy of defog_turn_test.csv'                 defog_walk_test_draft.csv\n",
            "'Copy of defog_walking.csv'                   MJFF-FOG-Prediction-PD.ipynb\n",
            "'Copy of defog_walking_test.csv'              tdcsfog_sh_draft.csv\n",
            "'Copy of tdcsfog_start_hesitation.csv'        tdcsfog_sh_test_draft.csv\n",
            "'Copy of tdcsfog_start_hesitation_test.csv'   tdcsfog_turn_draft.csv\n",
            "'Copy of tdcsfog_turn.csv'                    tdcsfog_turn_test_draft.csv\n",
            "'Copy of tdcsfog_turn_test.csv'               tdcsfog_walk_draft.csv\n",
            "'Copy of tdcsfog_walking.csv'                 tdcsfog_walk_test_draft.csv\n",
            "'Copy of tdcsfog_walking_test.csv'            \u001b[0m\u001b[01;34mTest\u001b[0m/\n",
            " defog_sh_draft.csv                           \u001b[01;34mtlvmc-parkinsons-freezing-gait-prediction\u001b[0m/\n",
            " defog_sh_test_draft.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tsflex seglearn tensorflow Keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsDmJ_Y9u3sJ",
        "outputId": "69a5fc39-56c0-4a73-85ed-22257527973c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tsflex\n",
            "  Downloading tsflex-0.4.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting seglearn\n",
            "  Downloading seglearn-1.2.5-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Collecting dill<0.4.0,>=0.3.8 (from tsflex)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess<0.71.0,>=0.70.16 (from tsflex)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from tsflex) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.10/dist-packages (from tsflex) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from tsflex) (4.66.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from seglearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seglearn) (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from Keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from Keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from Keras) (0.13.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->tsflex) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->tsflex) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1->tsflex) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seglearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seglearn) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->Keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->Keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->Keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Downloading tsflex-0.4.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seglearn-1.2.5-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill, multiprocess, tsflex, seglearn\n",
            "Successfully installed dill-0.3.9 multiprocess-0.70.17 seglearn-1.2.5 tsflex-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "from tsflex.features import FeatureCollection, MultipleFeatureDescriptors\n",
        "from tsflex.features.integrations import seglearn_feature_dict_wrapper\n",
        "from seglearn.feature_functions import base_features, emg_features\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "HHy0uGpPre5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_directory(directory):\n",
        "    dfs = []\n",
        "    for file_name in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, file_name)\n",
        "\n",
        "        # Check if the file is a CSV and process it\n",
        "        if file_name.endswith('.csv') and os.path.isfile(file_path):\n",
        "            df = pd.read_csv(file_path) #read csv files\n",
        "            df['source_directory'] = os.path.basename(directory)  # Add a column to identify the source directory\n",
        "            df['csv_name'] = os.path.basename(file_name)\n",
        "            dfs.append(df)\n",
        "\n",
        "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()"
      ],
      "metadata": {
        "id": "eUy_2H8qr8Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defog = process_directory('/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/train/defog')\n",
        "tdcsfog = process_directory('/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog')\n",
        "#notype = process_directory('/content/drive/MyDrive/Colab Notebooks/tlvmc-parkinsons-freezing-gait-prediction/train/notype')"
      ],
      "metadata": {
        "id": "nfQkZZvDsJQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/My Drive/Colab Notebooks/Test\"\n",
        "file_name = \"Copy of 3e6987cb2d.csv\"\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "defog_test = pd.read_csv(file_path)\n",
        "defog_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6mAHE52-Gfn",
        "outputId": "cb12c4aa-ee45-4527-c440-27f40d40ce55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300288, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/My Drive/Colab Notebooks/Test\"\n",
        "file_name = \"Copy of 3ba3590a08.csv\"\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "tdcsfog_test = pd.read_csv(file_path)\n",
        "tdcsfog_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHwEsTSp-HTR",
        "outputId": "4d5c39d2-ecc3-4597-b4f3-7231bfd3d314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46817, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the accelerometer data - defog training\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "fs = 100  # Sampling frequency in Hz\n",
        "\n",
        "# Define filter parameters\n",
        "lowcut = 0.25\n",
        "highcut = 10.0\n",
        "order = 4  # Filter order\n",
        "\n",
        "# Create a Butterworth bandpass filter\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "b, a = butter(order, [low, high], btype=\"band\")\n",
        "\n",
        "# Apply the filter to each accelerometer axis\n",
        "defog[\"AccV_filtered\"] = filtfilt(b, a, defog[\"AccV\"])\n",
        "defog[\"AccML_filtered\"] = filtfilt(b, a, defog[\"AccML\"])\n",
        "defog[\"AccAP_filtered\"] = filtfilt(b, a, defog[\"AccAP\"])\n",
        "\n",
        "print(defog.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khvls00jQPEa",
        "outputId": "3cd2d054-fef5-4d2a-c1aa-2d9f3d2fbf95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time  AccV     AccML  AccAP  StartHesitation  Turn  Walking  Valid   Task  \\\n",
            "0     0  -1.0  0.044129  -0.25                0     0        0  False  False   \n",
            "1     1  -1.0  0.034431  -0.25                0     0        0  False  False   \n",
            "2     2  -1.0  0.031250  -0.25                0     0        0  False  False   \n",
            "3     3  -1.0  0.031250  -0.25                0     0        0  False  False   \n",
            "4     4  -1.0  0.031250  -0.25                0     0        0  False  False   \n",
            "\n",
            "  source_directory        csv_name  AccV_filtered  AccML_filtered  \\\n",
            "0            defog  02ea782681.csv      -0.000051        0.000237   \n",
            "1            defog  02ea782681.csv      -0.000051       -0.004508   \n",
            "2            defog  02ea782681.csv      -0.000050       -0.008581   \n",
            "3            defog  02ea782681.csv      -0.000050       -0.011507   \n",
            "4            defog  02ea782681.csv      -0.000050       -0.013125   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0       -0.000733  \n",
            "1       -0.000764  \n",
            "2       -0.000796  \n",
            "3       -0.000829  \n",
            "4       -0.000864  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the accelerometer data - tdcsfog training\n",
        "\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "fs = 128  # Sampling frequency in Hz\n",
        "\n",
        "# Define filter parameters\n",
        "lowcut = 0.25\n",
        "highcut = 10.0\n",
        "order = 4  # Filter order\n",
        "\n",
        "# Create a Butterworth bandpass filter\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "b, a = butter(order, [low, high], btype=\"band\")\n",
        "\n",
        "# Apply the filter to each accelerometer axis\n",
        "tdcsfog[\"AccV_filtered\"] = filtfilt(b, a, tdcsfog[\"AccV\"])\n",
        "tdcsfog[\"AccML_filtered\"] = filtfilt(b, a, tdcsfog[\"AccML\"])\n",
        "tdcsfog[\"AccAP_filtered\"] = filtfilt(b, a, tdcsfog[\"AccAP\"])\n",
        "\n",
        "print(tdcsfog.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnUfCXoaQee1",
        "outputId": "491fd719-4998-4de3-941a-062e94f8949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time      AccV     AccML     AccAP  StartHesitation  Turn  Walking  \\\n",
            "0     0 -9.533939  0.566322 -1.413525                0     0        0   \n",
            "1     1 -9.536140  0.564137 -1.440621                0     0        0   \n",
            "2     2 -9.529345  0.561765 -1.429332                0     0        0   \n",
            "3     3 -9.531239  0.564227 -1.415490                0     0        0   \n",
            "4     4 -9.540825  0.561854 -1.429471                0     0        0   \n",
            "\n",
            "  source_directory        csv_name  AccV_filtered  AccML_filtered  \\\n",
            "0          tdcsfog  003f117e14.csv       0.001085        0.000978   \n",
            "1          tdcsfog  003f117e14.csv       0.000986       -0.000828   \n",
            "2          tdcsfog  003f117e14.csv       0.000908       -0.002730   \n",
            "3          tdcsfog  003f117e14.csv       0.000866       -0.004786   \n",
            "4          tdcsfog  003f117e14.csv       0.000860       -0.006998   \n",
            "\n",
            "   AccAP_filtered  \n",
            "0        0.006895  \n",
            "1        0.003350  \n",
            "2        0.000218  \n",
            "3       -0.002185  \n",
            "4       -0.003692  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering for defog_test\n",
        "fs = 100\n",
        "lowcut = 0.25\n",
        "highcut = 10.0\n",
        "order = 4\n",
        "\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "b, a = butter(order, [low, high], btype=\"band\")\n",
        "\n",
        "defog_test[\"AccV_filtered\"] = filtfilt(b, a, defog_test[\"AccV\"])\n",
        "defog_test[\"AccML_filtered\"] = filtfilt(b, a, defog_test[\"AccML\"])\n",
        "defog_test[\"AccAP_filtered\"] = filtfilt(b, a, defog_test[\"AccAP\"])"
      ],
      "metadata": {
        "id": "WPMWUa_hA49i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtering for tdcsfog_test\n",
        "fs = 128\n",
        "lowcut = 0.25\n",
        "highcut = 10.0\n",
        "order = 4\n",
        "\n",
        "nyquist = 0.5 * fs\n",
        "low = lowcut / nyquist\n",
        "high = highcut / nyquist\n",
        "b, a = butter(order, [low, high], btype=\"band\")\n",
        "\n",
        "tdcsfog_test[\"AccV_filtered\"] = filtfilt(b, a, tdcsfog_test[\"AccV\"])\n",
        "tdcsfog_test[\"AccML_filtered\"] = filtfilt(b, a, tdcsfog_test[\"AccML\"])\n",
        "tdcsfog_test[\"AccAP_filtered\"] = filtfilt(b, a, tdcsfog_test[\"AccAP\"])"
      ],
      "metadata": {
        "id": "ay56lKf1A5HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Windowing for defog\n",
        "def create_overlapping_windows(data, window_size, overlap, columns=['AccV_filtered', 'AccML_filtered', 'AccAP_filtered']):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        data (pd.DataFrame): Input DataFrame.\n",
        "        window_size (int): Number of samples in each window.\n",
        "        overlap (int): Number of overlapping samples between consecutive windows.\n",
        "        columns (list): Columns to extract for windows.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 3D tensor of shape (NSegments, window_size, len(columns)).\n",
        "    \"\"\"\n",
        "    step = window_size - overlap\n",
        "    windows = []\n",
        "    for start in range(0, len(data) - window_size + 1, step):\n",
        "        end = start + window_size\n",
        "        windows.append(data.iloc[start:end][columns].values)\n",
        "\n",
        "    return np.array(windows)\n",
        "\n",
        "# Parameters\n",
        "window_size = 300  # 3 seconds * 100 Hz\n",
        "overlap = 100      # 1 second * 100 Hz\n",
        "\n",
        "#defog_tensor = create_overlapping_windows(defog, window_size, overlap)\n",
        "\n",
        "#print(f\"Tensor shape: {defog_tensor.shape}\")  # Should be (NSegments, 300, 3)"
      ],
      "metadata": {
        "id": "2h5BMIlN8o1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Windowing for tdcsfog\n",
        "window_size = 384  # 3 seconds * 128 Hz\n",
        "overlap = 128      # 1 second * 128 Hz\n",
        "\n",
        "#tdcsfog_tensor = create_overlapping_windows(tdcsfog, window_size, overlap)\n",
        "\n",
        "#print(f\"Tensor shape: {tdcsfog_tensor.shape}\")  # Should be (NSegments, 300, 3)\n"
      ],
      "metadata": {
        "id": "KYYLkfB-9s1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "window_size = 300  # 3 seconds * 100 Hz\n",
        "overlap = 100      # 1 second * 100 Hz\n",
        "\n",
        "# Create overlapping windows for training and test data\n",
        "X_train = create_overlapping_windows(defog, window_size, overlap)\n",
        "X_test = create_overlapping_windows(defog_test, window_size, overlap)"
      ],
      "metadata": {
        "id": "uwgOBhYVAHKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(defog) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "    max(defog['Turn'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXxsNU1wD7E-",
        "outputId": "bbcf2cdb-40be-4b09-94f3-a542f5d565eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (66126, 300, 3), y_train shape: (66126, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(defog_test) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_test = [\n",
        "    max(defog_test['Turn'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkpiDwIZEwxI",
        "outputId": "0f1a9cc6-43b7-42f2-f7c3-cac02c9fa881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (1500, 300, 3), y_test shape: (1500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count label occurrences in y_train\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Training Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")\n",
        "\n",
        "# Count label occurrences in y_test\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"\\nTest Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673J3dGYCF31",
        "outputId": "3fc9c0b2-b928-4735-a97f-5907a27b5ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label Distribution:\n",
            "Label 0: 62086 samples\n",
            "Label 1: 4040 samples\n",
            "\n",
            "Test Label Distribution:\n",
            "Label 0: 1261 samples\n",
            "Label 1: 239 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training an LSTM model on defog\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=16,\n",
        "    class_weight=class_weight_dict,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(f\"Test Precision: {results[2]}\")\n",
        "print(f\"Test Recall: {results[3]}\")"
      ],
      "metadata": {
        "id": "cGUqFdpsSJxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726fd6dc-e69a-4831-e908-99f20adcfdc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m4133/4133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1051s\u001b[0m 253ms/step - Precision: 0.0622 - Recall: 0.4662 - accuracy: 0.5441 - loss: 0.6908 - val_Precision: 0.1593 - val_Recall: 1.0000 - val_accuracy: 0.1593 - val_loss: 0.6944\n",
            "Epoch 2/5\n",
            "\u001b[1m4133/4133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1049s\u001b[0m 240ms/step - Precision: 0.0602 - Recall: 0.3525 - accuracy: 0.6332 - loss: 0.6855 - val_Precision: 0.1593 - val_Recall: 1.0000 - val_accuracy: 0.1593 - val_loss: 0.7044\n",
            "Epoch 3/5\n",
            "\u001b[1m4133/4133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1050s\u001b[0m 242ms/step - Precision: 0.0610 - Recall: 0.6569 - accuracy: 0.3578 - loss: 0.6954 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.8407 - val_loss: 0.6862\n",
            "Epoch 4/5\n",
            "\u001b[1m4133/4133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1003s\u001b[0m 243ms/step - Precision: 0.0606 - Recall: 0.4844 - accuracy: 0.5036 - loss: 0.7005 - val_Precision: 0.1593 - val_Recall: 1.0000 - val_accuracy: 0.1593 - val_loss: 0.6978\n",
            "Epoch 5/5\n",
            "\u001b[1m4133/4133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1039s\u001b[0m 242ms/step - Precision: 0.0582 - Recall: 0.4153 - accuracy: 0.5609 - loss: 0.6881 - val_Precision: 0.1593 - val_Recall: 1.0000 - val_accuracy: 0.1593 - val_loss: 0.6981\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - Precision: 0.0517 - Recall: 0.8750 - accuracy: 0.0517 - loss: 0.6996\n",
            "Test Loss: 0.6980946660041809\n",
            "Test Accuracy: 0.15933333337306976\n",
            "Test Precision: 0.15933333337306976\n",
            "Test Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred_probs = model.predict(X_test).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Find optimal threshold (e.g., maximum TPR - FPR)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Apply threshold to predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "id": "2vzndC5mh-_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf3fe05-d740-4f2f-8068-7936ceb1acc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step\n",
            "Optimal Threshold: 0.5036123991012573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Predict binary labels\n",
        "#y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "2wPtNCkHj5vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b4e442-2df2-4e37-869a-d5ba10061b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      1261\n",
            "           1       0.33      0.35      0.34       239\n",
            "\n",
            "    accuracy                           0.78      1500\n",
            "   macro avg       0.60      0.61      0.60      1500\n",
            "weighted avg       0.79      0.78      0.79      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(defog) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "    max(defog['Walking'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "id": "oqICmikGG6kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27ecb04-8038-45f7-b2d1-95bb9d507981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (66126, 300, 3), y_train shape: (66126, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(defog_test) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_test = [\n",
        "    max(defog_test['Walking'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "plD-ckMpTee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ebf126-a37c-4d95-ff05-1979a17e6dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (1500, 300, 3), y_test shape: (1500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count label occurrences in y_train\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Training Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")\n",
        "\n",
        "# Count label occurrences in y_test\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"\\nTest Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QK-Op5kVoO_",
        "outputId": "7eca49c8-0ec0-4c95-8e09-c30f8a6858f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label Distribution:\n",
            "Label 0: 65288 samples\n",
            "Label 1: 838 samples\n",
            "\n",
            "Test Label Distribution:\n",
            "Label 0: 1486 samples\n",
            "Label 1: 14 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training an LSTM model on defog - walking\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(f\"Test Precision: {results[2]}\")\n",
        "print(f\"Test Recall: {results[3]}\")"
      ],
      "metadata": {
        "id": "aB4Pll8jTehm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2065870-c961-491f-93f1-771a6948cb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 283ms/step - Precision: 0.0107 - Recall: 0.2255 - accuracy: 0.7630 - loss: 0.6845 - val_Precision: 0.0093 - val_Recall: 1.0000 - val_accuracy: 0.0093 - val_loss: 0.7347\n",
            "Epoch 2/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 281ms/step - Precision: 0.0142 - Recall: 0.6789 - accuracy: 0.3858 - loss: 0.6914 - val_Precision: 0.0093 - val_Recall: 1.0000 - val_accuracy: 0.0093 - val_loss: 0.7024\n",
            "Epoch 3/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 275ms/step - Precision: 0.0119 - Recall: 0.4126 - accuracy: 0.5700 - loss: 0.6907 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.9907 - val_loss: 0.6918\n",
            "Epoch 4/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 274ms/step - Precision: 0.0128 - Recall: 0.5583 - accuracy: 0.4107 - loss: 0.7181 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.9907 - val_loss: 0.6677\n",
            "Epoch 5/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 275ms/step - Precision: 0.0094 - Recall: 0.1417 - accuracy: 0.8358 - loss: 0.6767 - val_Precision: 0.0093 - val_Recall: 1.0000 - val_accuracy: 0.0093 - val_loss: 0.7510\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - Precision: 0.0039 - Recall: 0.8750 - accuracy: 0.0039 - loss: 0.7516\n",
            "Test Loss: 0.7509821653366089\n",
            "Test Accuracy: 0.009333333000540733\n",
            "Test Precision: 0.009333333000540733\n",
            "Test Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred_probs = model.predict(X_test).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Find optimal threshold (e.g., maximum TPR - FPR)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Apply threshold to predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diacJSUjWMdK",
        "outputId": "77160939-4983-47bc-b156-0222580cecaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step\n",
            "Optimal Threshold: 0.5286065340042114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "dpEXWY2tTxSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a6064a-d10e-47d8-81cb-825b6584555a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.84      0.91      1486\n",
            "           1       0.02      0.36      0.04        14\n",
            "\n",
            "    accuracy                           0.84      1500\n",
            "   macro avg       0.51      0.60      0.48      1500\n",
            "weighted avg       0.98      0.84      0.90      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(defog) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "    max(defog['StartHesitation'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "id": "TIzrJ0v6Txaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6a089b-ff2b-45ec-ae21-9fa8b45fc35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (66126, 300, 3), y_train shape: (66126, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(defog_test) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_test = [\n",
        "    max(defog_test['StartHesitation'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "1pB9H1LmT7ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e767e93-196b-4dc9-c7eb-6b9deacfd374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (1500, 300, 3), y_test shape: (1500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training an LSTM model on defog - start hesitation\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(f\"Test Precision: {results[2]}\")\n",
        "print(f\"Test Recall: {results[3]}\")"
      ],
      "metadata": {
        "id": "AgHEEr9YTxrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fccbfcd7-0bc9-475c-aa72-b693072aa903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 280ms/step - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.9962 - loss: 2.0182 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.4866\n",
            "Epoch 2/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 286ms/step - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.9923 - loss: 0.7069 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.3498\n",
            "Epoch 3/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 284ms/step - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.9619 - loss: 0.9492 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.5482\n",
            "Epoch 4/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 280ms/step - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.9067 - loss: 0.8303 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.5153\n",
            "Epoch 5/5\n",
            "\u001b[1m2067/2067\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 281ms/step - Precision: 3.4379e-04 - Recall: 0.1441 - accuracy: 0.8458 - loss: 1.7634 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.1525\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 1.0000 - loss: 0.1525\n",
            "Test Loss: 0.15251725912094116\n",
            "Test Accuracy: 1.0\n",
            "Test Precision: 0.0\n",
            "Test Recall: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred_probs = model.predict(X_test).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Find optimal threshold (e.g., maximum TPR - FPR)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Apply threshold to predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ1Z8MJ4jDyV",
        "outputId": "b0965e54-d63d-4cda-8c35-af241d57a245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n",
            "Optimal Threshold: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py:1183: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "loqnDW2YUOeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f5455e-3a3a-4050-bf35-711ebc818611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1500\n",
            "\n",
            "    accuracy                           1.00      1500\n",
            "   macro avg       1.00      1.00      1.00      1500\n",
            "weighted avg       1.00      1.00      1.00      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TDCSFOG"
      ],
      "metadata": {
        "id": "lPYWdLfFUTSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "window_size = 384\n",
        "overlap = 128\n",
        "\n",
        "# Create overlapping windows for training and test data\n",
        "X_train = create_overlapping_windows(tdcsfog, window_size, overlap)\n",
        "X_test = create_overlapping_windows(tdcsfog_test, window_size, overlap)"
      ],
      "metadata": {
        "id": "FlAePi4bUVSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(tdcsfog) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "    max(tdcsfog['Turn'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_LmkbXexph2",
        "outputId": "1aaf63b0-c78d-45f9-f152-16c69fca213d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (27405, 384, 3), y_train shape: (27405, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(tdcsfog_test) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_test = [\n",
        "    max(tdcsfog_test['Turn'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeMr4v6TxtLI",
        "outputId": "98dc1308-7738-4e13-d140-8d5e50f26c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (182, 384, 3), y_test shape: (182, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count label occurrences in y_train\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Training Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")\n",
        "\n",
        "# Count label occurrences in y_test\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"\\nTest Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSVrkkU1xyi3",
        "outputId": "b4f540f3-4917-4be1-a597-eb291e1f0c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label Distribution:\n",
            "Label 0: 19680 samples\n",
            "Label 1: 7725 samples\n",
            "\n",
            "Test Label Distribution:\n",
            "Label 0: 68 samples\n",
            "Label 1: 114 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training an LSTM model on tdcsfog turn\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=16,\n",
        "    class_weight=class_weight_dict,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(f\"Test Precision: {results[2]}\")\n",
        "print(f\"Test Recall: {results[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbaQes1Ux2rK",
        "outputId": "9610695e-d2db-4fe5-fa82-f61d3198e730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 324ms/step - Precision: 0.3626 - Recall: 0.5524 - accuracy: 0.6027 - loss: 0.6631 - val_Precision: 0.6739 - val_Recall: 0.5439 - val_accuracy: 0.5495 - val_loss: 0.6908\n",
            "Epoch 2/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 325ms/step - Precision: 0.3282 - Recall: 0.5618 - accuracy: 0.5530 - loss: 0.6773 - val_Precision: 0.6298 - val_Recall: 1.0000 - val_accuracy: 0.6319 - val_loss: 0.6785\n",
            "Epoch 3/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 321ms/step - Precision: 0.2919 - Recall: 0.5847 - accuracy: 0.4862 - loss: 0.6904 - val_Precision: 0.6264 - val_Recall: 1.0000 - val_accuracy: 0.6264 - val_loss: 0.6840\n",
            "Epoch 4/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 310ms/step - Precision: 0.2934 - Recall: 0.6437 - accuracy: 0.4531 - loss: 0.6966 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.3736 - val_loss: 0.7010\n",
            "Epoch 5/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 309ms/step - Precision: 0.2685 - Recall: 0.3618 - accuracy: 0.5577 - loss: 0.6906 - val_Precision: 0.6264 - val_Recall: 1.0000 - val_accuracy: 0.6264 - val_loss: 0.6906\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - Precision: 0.4758 - Recall: 0.8571 - accuracy: 0.4758 - loss: 0.6939\n",
            "Test Loss: 0.6905806660652161\n",
            "Test Accuracy: 0.6263736486434937\n",
            "Test Precision: 0.6263736486434937\n",
            "Test Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred_probs = model.predict(X_test).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Find optimal threshold (e.g., maximum TPR - FPR)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Apply threshold to predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqqICjQ1yUqR",
        "outputId": "4c155fad-7707-41fb-ea07-0a9b28de80d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 773ms/step\n",
            "Optimal Threshold: 0.5060513019561768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test.flatten()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2qjwejF9Lfd",
        "outputId": "6ba2fea9-b6c3-4082-9e73-f6a273e68244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.90      0.54        68\n",
            "           1       0.71      0.15      0.25       114\n",
            "\n",
            "    accuracy                           0.43       182\n",
            "   macro avg       0.55      0.52      0.39       182\n",
            "weighted avg       0.59      0.43      0.36       182\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(tdcsfog) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "    max(tdcsfog['Walking'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya1H3q1H9SeA",
        "outputId": "cba2dba0-d4c9-4b99-d354-ddd31832dd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (27405, 384, 3), y_train shape: (27405, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(tdcsfog_test) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_test = [\n",
        "    max(tdcsfog_test['Walking'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxQSOqv4-a4f",
        "outputId": "ae9c7466-2fbc-4773-c544-50959f295671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (182, 384, 3), y_test shape: (182, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count label occurrences in y_train\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Training Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")\n",
        "\n",
        "# Count label occurrences in y_test\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"\\nTest Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD3O7cT--f2H",
        "outputId": "8ea0e634-9b73-491d-b549-bec603940f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label Distribution:\n",
            "Label 0: 26454 samples\n",
            "Label 1: 951 samples\n",
            "\n",
            "Test Label Distribution:\n",
            "Label 0: 164 samples\n",
            "Label 1: 18 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training an LSTM model on tdcsfog walking\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=16,\n",
        "    class_weight=class_weight_dict,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(f\"Test Precision: {results[2]}\")\n",
        "print(f\"Test Recall: {results[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605u1F4M-kTX",
        "outputId": "3c32c8fc-111d-4802-b854-e7101b50699e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 331ms/step - Precision: 0.0376 - Recall: 0.4329 - accuracy: 0.6146 - loss: 0.6853 - val_Precision: 0.1000 - val_Recall: 1.0000 - val_accuracy: 0.1099 - val_loss: 0.7447\n",
            "Epoch 2/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 310ms/step - Precision: 0.0391 - Recall: 0.7622 - accuracy: 0.3117 - loss: 0.7037 - val_Precision: 0.0989 - val_Recall: 1.0000 - val_accuracy: 0.0989 - val_loss: 0.7232\n",
            "Epoch 3/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 306ms/step - Precision: 0.0347 - Recall: 0.7177 - accuracy: 0.2762 - loss: 0.7071 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.9011 - val_loss: 0.5842\n",
            "Epoch 4/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 305ms/step - Precision: 0.0461 - Recall: 0.5039 - accuracy: 0.5329 - loss: 0.6836 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.8681 - val_loss: 0.6903\n",
            "Epoch 5/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 302ms/step - Precision: 0.0327 - Recall: 0.4580 - accuracy: 0.5274 - loss: 0.6923 - val_Precision: 0.0000e+00 - val_Recall: 0.0000e+00 - val_accuracy: 0.9011 - val_loss: 0.5951\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - Precision: 0.0000e+00 - Recall: 0.0000e+00 - accuracy: 0.9664 - loss: 0.5774\n",
            "Test Loss: 0.595101535320282\n",
            "Test Accuracy: 0.901098906993866\n",
            "Test Precision: 0.0\n",
            "Test Recall: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred_probs = model.predict(X_test).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Find optimal threshold (e.g., maximum TPR - FPR)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Apply threshold to predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfaUg7T4-ub5",
        "outputId": "e5dc5556-9df7-43e9-89d3-6765d8081027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step\n",
            "Optimal Threshold: 0.43967127799987793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiWuOPtS-0IM",
        "outputId": "9900c640-d3b3-4fd5-f6eb-10c150d723e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.91       164\n",
            "           1       0.07      0.06      0.06        18\n",
            "\n",
            "    accuracy                           0.83       182\n",
            "   macro avg       0.48      0.49      0.48       182\n",
            "weighted avg       0.82      0.83      0.82       182\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(tdcsfog) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_train = [\n",
        "    max(tdcsfog['StartHesitation'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMgsuoHIaHaR",
        "outputId": "87539b3d-c715-4eaa-9164-fcda88d82caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (27405, 384, 3), y_train shape: (27405, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate window indices\n",
        "step = window_size - overlap\n",
        "windows_indices = [\n",
        "    (start, start + window_size)\n",
        "    for start in range(0, len(tdcsfog_test) - window_size + 1, step)\n",
        "]\n",
        "\n",
        "y_test = [\n",
        "    max(tdcsfog_test['StartHesitation'][start:end])\n",
        "    for start, end in windows_indices\n",
        "]\n",
        "\n",
        "# Convert y_train to a numpy array\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        "\n",
        "# Verify shapes\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-nc_VCSalb9",
        "outputId": "a1778918-b33f-4db5-ff29-45e23c354ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (182, 384, 3), y_test shape: (182, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count label occurrences in y_train\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Training Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")\n",
        "\n",
        "# Count label occurrences in y_test\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"\\nTest Label Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Label {label}: {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3eWAr_earPe",
        "outputId": "473c9b9c-69d3-4433-9a09-a39419f66d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Label Distribution:\n",
            "Label 0: 26118 samples\n",
            "Label 1: 1287 samples\n",
            "\n",
            "Test Label Distribution:\n",
            "Label 0: 136 samples\n",
            "Label 1: 46 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training an LSTM model on tdcsfog sh\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train.flatten())\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='tanh'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,\n",
        "    batch_size=16,\n",
        "    class_weight=class_weight_dict,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(f\"Test Precision: {results[2]}\")\n",
        "print(f\"Test Recall: {results[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSdpL0UavYu",
        "outputId": "63996e09-d5c5-4d7a-b7f0-4501ae95dded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 311ms/step - Precision: 0.0591 - Recall: 0.6023 - accuracy: 0.5271 - loss: 0.6811 - val_Precision: 0.2552 - val_Recall: 0.8043 - val_accuracy: 0.3571 - val_loss: 0.9868\n",
            "Epoch 2/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m521s\u001b[0m 304ms/step - Precision: 0.1294 - Recall: 0.5839 - accuracy: 0.7963 - loss: 0.5969 - val_Precision: 0.1895 - val_Recall: 0.3913 - val_accuracy: 0.4231 - val_loss: 1.0025\n",
            "Epoch 3/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 306ms/step - Precision: 0.0862 - Recall: 0.7695 - accuracy: 0.5870 - loss: 0.6262 - val_Precision: 0.2481 - val_Recall: 0.7174 - val_accuracy: 0.3791 - val_loss: 1.0188\n",
            "Epoch 4/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 303ms/step - Precision: 0.1343 - Recall: 0.6713 - accuracy: 0.7759 - loss: 0.5688 - val_Precision: 0.2597 - val_Recall: 0.8696 - val_accuracy: 0.3407 - val_loss: 0.9875\n",
            "Epoch 5/5\n",
            "\u001b[1m1713/1713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 303ms/step - Precision: 0.0731 - Recall: 0.6516 - accuracy: 0.5714 - loss: 0.6482 - val_Precision: 0.2922 - val_Recall: 0.9783 - val_accuracy: 0.3956 - val_loss: 0.7456\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - Precision: 0.4904 - Recall: 0.9814 - accuracy: 0.5350 - loss: 0.7089\n",
            "Test Loss: 0.7456268668174744\n",
            "Test Accuracy: 0.3956044018268585\n",
            "Test Precision: 0.2922077775001526\n",
            "Test Recall: 0.97826087474823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "y_pred_probs = model.predict(X_test).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "# Find optimal threshold (e.g., maximum TPR - FPR)\n",
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Apply threshold to predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYD8cSVAa38m",
        "outputId": "7e6d995b-fe87-49ff-e00b-58db8136ae80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step\n",
            "Optimal Threshold: 0.5200673341751099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JugJDk3La8An",
        "outputId": "0fce01bb-5242-434c-8492-b811248b9b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.26      0.40       136\n",
            "           1       0.30      0.93      0.45        46\n",
            "\n",
            "    accuracy                           0.43       182\n",
            "   macro avg       0.61      0.60      0.43       182\n",
            "weighted avg       0.76      0.43      0.42       182\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55OO-Pwjq5vP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}